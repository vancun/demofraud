{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize app config\n",
    "import importlib\n",
    "from demolib import schema, cfg, spark\n",
    "from demolib.functions import earth_distance\n",
    "from demolib.mongo import *\n",
    "from demolib.udf import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer information from source CSV file\n",
    "# _id column is added to make load job idempotent.\n",
    "customer_df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .csv('{}/{}'.format(cfg.load.dir, cfg.load.customer), schema = schema.customer.schema) \\\n",
    "    .withColumn('_id', expr(\"cc_num || '+' || first || '+' || last\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add customer age column to customer data\n",
    "customer_age_df = customer_df.withColumn(\"age\", udf_age())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+--------+------+--------------------+--------------+-----+-----+-------+---------+--------------------+-------------------+--------------------+---+\n",
      "|          cc_num|  first|    last|gender|              street|          city|state|  zip|    lat|     long|                 job|                dob|                 _id|age|\n",
      "+----------------+-------+--------+------+--------------------+--------------+-----+-----+-------+---------+--------------------+-------------------+--------------------+---+\n",
      "|3526015186182660|   Carl|   Gomez|     M|204 Cohen Meadow ...|Hathaway Pines|   CA|95233|38.1919|-120.3644|Data processing m...|1958-10-11 19:30:00|3526015186182660+...| 60|\n",
      "|4170242670039985|Rebecca|Trujillo|     F|       242 Cody Pass|      Colstrip|   MT|59323|45.9344|-106.6368|          Air broker|1983-08-08 20:30:00|4170242670039985+...| 36|\n",
      "+----------------+-------+--------+------+--------------------+--------------+-----+-----+-------+---------+--------------------+-------------------+--------------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_age_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transactions from source CSV file\n",
    "raw_transaction_df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .csv('{}/{}'.format(cfg.load.dir, cfg.load.transaction), schema = schema.transaction.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_date column from the source data is stored as timestamp with 00:00:00 time\n",
    "# Convert trans_date to date and transform trans_time column to timestamp column.\n",
    "transaction_df = raw_transaction_df \\\n",
    "    .withColumn(\"trans_date\", split(col(\"trans_date\"), \"T\")[0]) \\\n",
    "    .withColumn(\"trans_time\", concat_ws(\" \", col(\"trans_date\"), col(\"trans_time\"))) \\\n",
    "    .withColumn(\"trans_time\", to_timestamp(col(\"trans_time\"), \"YYYY-MM-dd HH:mm:ss\").cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF function from our Python function\n",
    "# dist_udf = udf(earth_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join transactions to customers to compute the distance\n",
    "# project only columns that we want to export\n",
    "processed_transactions_df = transaction_df.join(broadcast(customer_age_df), \"cc_num\") \\\n",
    "    .withColumn(\"distance\", lit(round(udf_dist(col(\"lat\"), col(\"long\"), (\"merch_lat\"), col(\"merch_long\")), 2))) \\\n",
    "    .select(\"cc_num\", \"trans_num\", \"trans_time\", \"category\", \"merchant\", \"amt\", \"merch_lat\", \"merch_long\", \"distance\", \"age\", \"is_fraud\") \\\n",
    "    .withColumn(\"_id\", col(\"trans_num\")) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From transactions filter fraud transactions and nonfraud transactions in separate DataFrame objects\n",
    "fraud_transactions_df = processed_transactions_df.where(\"is_fraud = 1\")\n",
    "nonfraud_transactions_df = processed_transactions_df.where(\"is_fraud = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store customer data into MongoDB collection\n",
    "# Because we defined _id column write performs \"upser\"\n",
    "_ = mongo_save(customer_df, collection=cfg.db.customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fraud transactions into MongoDB collection\n",
    "# Writes are idempotent (upserts) due to _id column.\n",
    "_ = mongo_save(fraud_transactions_df, collection=cfg.db.fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store non-fraud transactions into MongoDB collection\n",
    "# Writes are idempotent (upserts) due to _id column.\n",
    "_ = mongo_save(nonfraud_transactions_df, collection=cfg.db.nonfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original transactions into MongoDB for study purposees\n",
    "_ = mongo_save(transaction_df, collection=cfg.db.transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
